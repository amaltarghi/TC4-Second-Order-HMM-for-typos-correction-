{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# source: http://norvig.com/spell-correct.html\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "WORDS = Counter(words(open('/home/anonyme/Documents/TC4-Second-Order-HMM-for-typos-correction-/typos-data /big.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "#words on the training base (in our case is big.txt)\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spelling'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deletion case\n",
    "correction('speling')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corrected'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('korrectud')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insersion\n",
    "correction ('athe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feelings'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction ('feeljhgs') # hmm2 was not able to correct it : insersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected ones are 6593\n",
      "total is 7320\n",
      "Accuarcy is 90.06830601092896 %\n",
      "Error is 9.931693989071036 %\n"
     ]
    }
   ],
   "source": [
    "test10 =  pickle.load(open('/home/anonyme/Documents/TC4-Second-Order-HMM-for-typos-correction-/typos-data /test10.pkl', 'rb'))\n",
    "correct=0\n",
    "total=0\n",
    "#the idea is to add our states to big.txt\n",
    "\n",
    "file = open(\"/home/anonyme/Documents/TC4-Second-Order-HMM-for-typos-correction-/typos-data /file.txt\", \"w\")\n",
    "for i in test10:\n",
    "    # map a list of tuples to 2 lists\n",
    "    flist1, list2 = zip(*i)\n",
    "    # map a tuple to string\n",
    "    obs = ''.join(flist1)\n",
    "    #print a\n",
    "    state = ''.join(list2)\n",
    "    corr = correction(obs)\n",
    "    file.write(state + \" \")\n",
    "    if state==corr:\n",
    "        correct+= len(corr)\n",
    "    total+=len(state)\n",
    "file.close() \n",
    "    \n",
    " \n",
    "    \n",
    "print('corrected ones are ' +str(correct))\n",
    "print('total is ' +str(total))\n",
    "\n",
    "print (\"Accuarcy is \" +str(correct*100.0/total ) + \" %\")\n",
    "print (\"Error is \" +str(100 - correct*100.0/total ) + \" %\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
